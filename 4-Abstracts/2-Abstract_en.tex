%----------------------------------------------------------------------
% 英文摘要
%----------------------------------------------------------------------

% 把英文摘要寫在裡面
\begin{enAbstract}

    Lung cancer has long been the leading cause of cancer-related deaths in Taiwan. Its pronounced heterogeneity and uncertain prognosis make survival risk prediction particularly challenging. Digital pathology images, which serve as high-fidelity representations of tumor tissues, offer a non-invasive and potentially informative source for prognostic evaluation, carrying significant clinical value. In recent years, foundation models have demonstrated strong potential in medical image analysis; however, their application to practical clinical tasks such as survival analysis still requires tailored adaptation and enhancement.

    This study aims to improve the performance of foundation models for survival risk prediction in lung cancer pathology images through multi-scale image fusion, multi-modal feature integration, and low-rank adaptation (LoRA) techniques. We first design a multi-scale input mechanism for whole slide images, combining low- and high-magnification views. These are integrated via cross-attention to enable the model to understand tumor structure and its surrounding microenvironment at different levels. To further enhance the model’s ability to perceive tumor biological heterogeneity, we incorporate cell-level morphological features and fuse them with the image-derived features, allowing the model to simultaneously capture macro- and micro-level prognostic cues.
    
    For the model architecture, a large-scale foundation model is used as the encoder, coupled with a gated-attention multiple instance learning (MIL) mechanism for weakly supervised patient-level survival prediction. The MIL framework enables the model to focus on prognostically relevant local regions, and in combination with the rich representations from the foundation model, facilitates learning of key tumor subregions. Additionally, LoRA is introduced to adapt the foundation model with minimal parameter updates, improving training efficiency and generalizability, especially in scenarios with limited medical data.
    
    Experiments were conducted using pathology images and clinical data from approximately 300 patients in the TCGA-LUAD cohort. The model was trained using the Cox Proportional Hazards loss function, achieving a C-index of 0.66 on the test set—substantially outperforming the unadapted foundation model. Overall, this study demonstrates how the integration of multi-scale and multi-modal features, MIL mechanisms, and LoRA fine-tuning can effectively enhance the adaptability and predictive performance of foundation models in lung cancer survival analysis. The findings offer new research directions and model paradigms for future intelligent pathology applications.
    
    % 這個Command會自動幫你把Config裡面設定的東東填進來    
    \enAbsKeywords
\end{enAbstract}
